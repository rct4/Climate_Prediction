{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53d09ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\19713\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\19713\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\19713\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\19713\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\19713\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\19713\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: gensim in c:\\users\\19713\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\19713\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\19713\\anaconda3\\lib\\site-packages (from gensim) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\19713\\anaconda3\\lib\\site-packages (from gensim) (1.21.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef8ddaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    " \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64241e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>Valid Date</th>\n",
       "      <th>Valid Time</th>\n",
       "      <th>State</th>\n",
       "      <th>Cities</th>\n",
       "      <th>Counties</th>\n",
       "      <th>Dirty</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>2002-01-30</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"event narrative\": \"Totals:00300.000M0.00K\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>2002-01-30</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"event narrative\": \"Totals:000.00K0.00K\", \"c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>2002-03-09</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"event narrative\": \"Totals:000.00K0.00K\", \"c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fire</td>\n",
       "      <td>2002-07-20</td>\n",
       "      <td>12:40:00</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>2002-08-28</td>\n",
       "      <td>14:09:00</td>\n",
       "      <td>Florida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"event narrative\": \"Totals:000.00K0.00K\", \"c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Hurricane Lily</td>\n",
       "      <td>2002-10-03</td>\n",
       "      <td>3:33:00</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"event narrative\": \"Totals:00149.655M0.00K\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Winter Storm</td>\n",
       "      <td>2002-11-06</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>2002-11-17</td>\n",
       "      <td>6:00:00</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Ice Storm</td>\n",
       "      <td>2002-12-03</td>\n",
       "      <td>18:30:00</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"event narrative\": \"Totals:1010.045M0.00K\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Winter Storm</td>\n",
       "      <td>2002-12-11</td>\n",
       "      <td>13:09:00</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Fredericksburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[{\"event narrative\": \"Totals:000.00K0.00K\", \"c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Event Type  Valid Date Valid Time        State  \\\n",
       "0           0       Ice Storm  2002-01-30    6:00:00     Oklahoma   \n",
       "1           1       Ice Storm  2002-01-30   16:00:00     Missouri   \n",
       "2           2  Severe Weather  2002-03-09    0:00:00     Michigan   \n",
       "3           3            Fire  2002-07-20   12:40:00     New York   \n",
       "4           4  Severe Weather  2002-08-28   14:09:00      Florida   \n",
       "5           5  Hurricane Lily  2002-10-03    3:33:00    Louisiana   \n",
       "6           6    Winter Storm  2002-11-06   22:00:00   California   \n",
       "7           7       Ice Storm  2002-11-17    6:00:00  Connecticut   \n",
       "8           8       Ice Storm  2002-12-03   18:30:00     Arkansas   \n",
       "9           9    Winter Storm  2002-12-11   13:09:00     Virginia   \n",
       "\n",
       "           Cities Counties Dirty  \\\n",
       "0             NaN      NaN   NaN   \n",
       "1             NaN      NaN   NaN   \n",
       "2             NaN      NaN     1   \n",
       "3             NaN      NaN   NaN   \n",
       "4             NaN      NaN   NaN   \n",
       "5             NaN      NaN     1   \n",
       "6             NaN      NaN     1   \n",
       "7             NaN      NaN     1   \n",
       "8             NaN      NaN   NaN   \n",
       "9  Fredericksburg      NaN     1   \n",
       "\n",
       "                                         description  \n",
       "0  [{\"event narrative\": \"Totals:00300.000M0.00K\",...  \n",
       "1  [{\"event narrative\": \"Totals:000.00K0.00K\", \"c...  \n",
       "2  [{\"event narrative\": \"Totals:000.00K0.00K\", \"c...  \n",
       "3                                                 []  \n",
       "4  [{\"event narrative\": \"Totals:000.00K0.00K\", \"c...  \n",
       "5  [{\"event narrative\": \"Totals:00149.655M0.00K\",...  \n",
       "6                                                 []  \n",
       "7                                                 []  \n",
       "8  [{\"event narrative\": \"Totals:1010.045M0.00K\", ...  \n",
       "9  [{\"event narrative\": \"Totals:000.00K0.00K\", \"c...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/all_weather_events_labeled_v2.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec08f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_label_probabilities(description):\n",
    "    \n",
    "    freq = {}\n",
    "    for event in description:\n",
    "        event_type = event['event type']\n",
    "        if event_type in freq:\n",
    "            freq[event_type] += (1 / len(description))\n",
    "        else:\n",
    "            freq[event_type] = 1 / len(description)\n",
    "    max_event = sorted((zip(freq.values(), freq.keys())), reverse=True)\n",
    "    return max_event\n",
    "    \n",
    "        \n",
    "def plot_label_probabilities(description):\n",
    "    val = calculate_label_probabilities(json.loads(description))\n",
    "    print(val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "290be666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severe Thunderstorms\n",
      "[(0.5465116279069774, 'Thunderstorm Wind'), (0.40116279069767485, 'Hail'), (0.03488372093023256, 'Lightning'), (0.01744186046511628, 'Heavy Rain')]\n"
     ]
    }
   ],
   "source": [
    "index = 18\n",
    "true_label = df['Event Type'][index]\n",
    "print(true_label)\n",
    "plot_label_probabilities(df['description'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33688914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602, 2325)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = df[~df['Event Type'].str.contains('Severe Weather', na=False)]\n",
    "len(labeled), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1917b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         (0.9090909090909085, Ice Storm)\n",
      "1         (0.4883720930232556, Ice Storm)\n",
      "3                                   (0, )\n",
      "5                                   (0, )\n",
      "6                                   (0, )\n",
      "7                                   (0, )\n",
      "8         (0.6470588235294118, Ice Storm)\n",
      "9                                   (0, )\n",
      "10    (0.09090909090909091, Winter Storm)\n",
      "11    (0.25925925925925924, Winter Storm)\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Using the non-severe labels, we can iterate and see how well the labels match. We calculate the matching as follows:\n",
    "\n",
    "# First, let's see how many entries directly have a NOAA label that matches the true label\n",
    "\n",
    "\n",
    "def determine_match(orig_label, label_list):\n",
    "    for label_id, label in label_list:  # This makes it clear we're iterating through tuples\n",
    "        if orig_label == label:\n",
    "            return (label_id, label)\n",
    "    return (0, '')\n",
    "\n",
    "match = labeled.apply(lambda row: determine_match(row['Event Type'], calculate_label_probabilities(json.loads(row['description']))), axis=1)\n",
    "\n",
    "print(match.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "37fd1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1079734219269103\n"
     ]
    }
   ],
   "source": [
    "sum_success = match.apply(lambda x: x[0] != 0)\n",
    "print(sum_success.sum() / len(sum_success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "86ef6c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======--------------------------------------------] 12.2% 202.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============-------------------------------------] 27.6% 459.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================----------------------------] 44.7% 743.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 53.5% 890.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================---------------------] 59.8% 995.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 72.1% 1198.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 78.7% 1309.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Evidently not great results, but not that bad considering that it is natural language. Let's try a more adaptable method\n",
    "import gensim.downloader\n",
    "glove_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4e38099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "def phrase_vector(phrase, model):\n",
    "    words = phrase.split(' ')\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return None  # No word in the phrase was found in the model\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "def semantic_similarity(phrase1, phrase2, model):\n",
    "    vector1 = phrase_vector(phrase1, model)\n",
    "    vector2 = phrase_vector(phrase2, model)\n",
    "    if vector1 is not None and vector2 is not None:\n",
    "        return 1 - cosine(vector1, vector2)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def determine_match(orig_label, label_list):\n",
    "    \n",
    "    if (len(label_list) == 0):\n",
    "        return (0,'',[])\n",
    "    weighted_similarity = []\n",
    "    for label_prob, label in label_list:  # This makes it clear we're iterating through tuples\n",
    "        sim = semantic_similarity(orig_label, label, glove_vectors)\n",
    "        weighted_similarity.append(label_prob * sim)\n",
    "    return (np.mean(weighted_similarity), orig_label, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7aa174e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (0.4909076582301744, Ice Storm, [(0.9090909090...\n",
       "1      (0.25946104064468256, Ice Storm, [(0.488372093...\n",
       "3                                              (0, , [])\n",
       "5      (0.14029594796135064, Hurricane Lily, [(0.3829...\n",
       "6                                              (0, , [])\n",
       "                             ...                        \n",
       "97     (0.17184855062514545, Hurricane Charley, [(0.5...\n",
       "98     (0.23348242186364673, Hurricane Charley, [(0.5...\n",
       "99     (0.23192569743032035, Tropical Storm Gaston, [...\n",
       "100    (0.25334964195887244, Tropical Storm Gaston, [...\n",
       "101    (0.11741991804705726, Tropical Storm Gaston, [...\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = labeled.apply(lambda row: determine_match(row['Event Type'], calculate_label_probabilities(json.loads(row['description']))), axis=1)\n",
    "match.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d25d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
